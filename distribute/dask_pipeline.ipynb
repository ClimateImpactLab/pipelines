{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "from dask import do\n",
    "from dask.multiprocessing import get\n",
    "from time import time\n",
    "import numpy as np\n",
    "import metacsv\n",
    "import csv\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import xarray as xr\n",
    "import copy\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in csvv\n",
    "def read(filename):\n",
    "    with open(filename, 'rU') as fp:\n",
    "        attrs, coords, variables = metacsv.read_header(fp, parse_vars=True)\n",
    "        data = {'attrs': attrs, 'variables': variables, 'coords': coords}\n",
    "\n",
    "        if 'csvv-version' in attrs:\n",
    "            if attrs['csvv-version'] == 'girdin-2017-01-10':\n",
    "                return read_girdin(data, fp)\n",
    "\n",
    "\n",
    "def read_girdin(data, fp):\n",
    "    reader = csv.reader(fp)\n",
    "    variable_reading = None\n",
    "\n",
    "    for row in reader:\n",
    "        if len(row) == 0 or (len(row) == 1 and len(row[0].strip()) == 0):\n",
    "            continue\n",
    "\n",
    "        if row[0] in ['observations', 'prednames', 'covarnames', 'gamma', 'gammavcv', 'residvcv']:\n",
    "            data[row[0]] = []\n",
    "            variable_reading = row[0]\n",
    "        else:\n",
    "            if variable_reading is None:\n",
    "                print \"No variable queued.\"\n",
    "                print row\n",
    "            assert variable_reading is not None\n",
    "            data[variable_reading].append(map(lambda x: x.strip(), row))\n",
    "\n",
    "    data['observations'] = float(data['observations'][0][0])\n",
    "    data['prednames'] = data['prednames'][0]\n",
    "    data['covarnames'] = data['covarnames'][0]\n",
    "    data['gamma'] = np.array(map(float, data['gamma'][0]))\n",
    "    data['gammavcv'] = np.array(map(lambda row: map(float, row), data['gammavcv']))\n",
    "    data['residvcv'] = np.array(map(lambda row: map(float, row), data['residvcv']))\n",
    "\n",
    "    return data\n",
    "\n",
    "def subset(csvv, prednames):\n",
    "    toinclude = map(lambda predname: predname in prednames, csvv['prednames'])\n",
    "    toinclude = np.where(toinclude)[0]\n",
    "\n",
    "    subcsvv = copy.copy(csvv)\n",
    "    subcsvv['prednames'] = [csvv['prednames'][ii] for ii in toinclude]\n",
    "    subcsvv['covarnames'] = [csvv['covarnames'][ii] for ii in toinclude]\n",
    "    subcsvv['gamma'] = csvv['gamma'][toinclude]\n",
    "    if 'gammavcv' in csvv and csvv['gammavcv'] is not None:\n",
    "        subcsvv['gammavcv'] = csvv['gammavcv'][toinclude, toinclude]\n",
    "\n",
    "    return subcsvv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attrs': Attributes\n",
       "     oneline:        Mortality rate temperature MLE spline 8 knots GMFD 2 factor\n",
       "     version:        Mortality_MLE_splines_GMFD2factor_2017_03_21\n",
       "     dependencies:   GCP_Reanalysis\\Mortality\\MLE\\data\\mortality_AEA\n",
       "     description:    MLE, GMFD2factor spline model, 8 knots -12,-7,0,10,18,2...\n",
       "     csvv-version:   girdin-2017-01-10,\n",
       " 'coords': <Empty Coordinates>,\n",
       " 'covarnames': ['1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  'climtas',\n",
       "  'climtas',\n",
       "  'climtas',\n",
       "  'climtas',\n",
       "  'climtas',\n",
       "  'climtas',\n",
       "  'climtas',\n",
       "  'loggdppc',\n",
       "  'loggdppc',\n",
       "  'loggdppc',\n",
       "  'loggdppc',\n",
       "  'loggdppc',\n",
       "  'loggdppc',\n",
       "  'loggdppc'],\n",
       " 'gamma': array([  4.44224278e-01,  -5.46965000e-04,   4.41760000e-04,\n",
       "         -2.06169000e-04,   1.90692000e-04,   1.90872156e-01,\n",
       "          9.18037326e+00,   1.06382992e-01,   6.64540470e-02,\n",
       "          7.00468900e-02,   6.76762480e-02,   3.24889000e-02,\n",
       "         -1.01764476e-01,  -1.60632614e-01,  -4.64026714e-01,\n",
       "         -3.75326097e-01,  -3.50358610e-01,  -4.74830884e-01,\n",
       "         -4.40626677e-01,  -5.72285489e-01,  -8.05625403e-01]),\n",
       " 'gammavcv': array([  2.50364600e-03,  -9.81381000e-10,   2.09601000e-09,\n",
       "         -1.77373000e-09,  -7.50852000e-09,   2.15111800e-03,\n",
       "          6.95727800e+00,   4.63133000e-04,   2.34758000e-04,\n",
       "          9.30961000e-04,   1.90361600e-03,   6.15314700e-03,\n",
       "          3.78325100e-03,   2.50212000e-03,   8.29021000e-04,\n",
       "          1.93614400e-03,   6.65439100e-03,   1.21814100e-02,\n",
       "          2.04243100e-02,   2.86184700e-02,   1.87233300e-02]),\n",
       " 'observations': 800.0,\n",
       " 'prednames': ['spline_variables-0',\n",
       "  'spline_variables-1',\n",
       "  'spline_variables-2',\n",
       "  'spline_variables-3',\n",
       "  'spline_variables-4',\n",
       "  'spline_variables-5',\n",
       "  'spline_variables-6',\n",
       "  'spline_variables-0',\n",
       "  'spline_variables-1',\n",
       "  'spline_variables-2',\n",
       "  'spline_variables-3',\n",
       "  'spline_variables-4',\n",
       "  'spline_variables-5',\n",
       "  'spline_variables-6',\n",
       "  'spline_variables-0',\n",
       "  'spline_variables-1',\n",
       "  'spline_variables-2',\n",
       "  'spline_variables-3',\n",
       "  'spline_variables-4',\n",
       "  'spline_variables-5',\n",
       "  'spline_variables-6'],\n",
       " 'residvcv': array([], dtype=float64),\n",
       " 'variables': Variables\n",
       "     spline_variables-1: \n",
       "         description     2nd term of cubic splines\n",
       "     loggdppc:  \n",
       "         description     GDP per capita\n",
       "         unit            log USD2000\n",
       "     spline_variables-4: \n",
       "         description     5th term of cubic splines\n",
       "     spline_variables-5: \n",
       "         description     6th term of cubic splines\n",
       "     climtas:   \n",
       "         description     Long term average temperature\n",
       "         unit            C\n",
       "     outcome:   \n",
       "         description     Death Per 100,000\n",
       "         unit            100,000 * death/population\n",
       "     spline_variables-0: \n",
       "         description     term 0 of cubic splines, equivalent to the yearly s...\n",
       "         unit            C\n",
       "     spline_variables-6: \n",
       "         description     7th term of cubic splines\n",
       "     spline_variables-2: \n",
       "         description     3rd term of cubic splines\n",
       "     spline_variables-3: \n",
       "         description     4th term of cubic splines}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvv = read('/Users/rhodiumgroup/data/gcp_stuff/MLE_splines_GMFD_03212017.csvv')\n",
    "prednames = ['spline_variables-0','spline_variables-1','spline_variables-2','spline_variables-3','spline_variables-4','spline_variables-5','spline_variables-6','spline_variables-0','spline_variables-1','spline_variables-2','spline_variables-3','spline_variables-4','spline_variables-5','spline_variables-6','spline_variables-0','spline_variables-1','spline_variables-2','spline_variables-3','spline_variables-4','spline_variables-5','spline_variables-6']\n",
    "subsetted = subset(csvv, prednames)\n",
    "subsetted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csvv_labor = read('/Users/rhodiumgroup/data/gcp_stuff/labor_global_interaction_2factor_BEST_14feb.csvv')\n",
    "prednames_labor = ['tasmax', 'tasmax2','tasmax3', 'tasmax4']\n",
    "subsetted = subset(csvv_labor, prednames_labor)\n",
    "#subsetted['covarnames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in annual climate data\n",
    "def do_climate_thing(path,climate_args, resample_time, resample_how):\n",
    "    \n",
    "    t1 = time()\n",
    "    year = re.search(r'(\\d{4})', path).group(0)\n",
    "    regexed = pd.date_range(str(year), periods=365)\n",
    "    \n",
    "    ds = xr.open_dataset(path)\n",
    "    ds['time'] = regexed\n",
    "    ds = ds.resample(resample_time, 'time', how=resample_how)\n",
    "    t2 = time()\n",
    "    print(\"do_climate_thing {}\".format(t2-t1))\n",
    "    return ds[climate_args], year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_global_gamma_estimates(path_to_csvv, pvals,prednames):\n",
    "    t1 = time()\n",
    "    csvv = read(path_to_csvv)\n",
    "    subsetted = subset(csvv, prednames)\n",
    "    np.random.seed(pvals)\n",
    "    p_adjusted_gammas = scipy.stats.multivariate_normal.rvs(subsetted['gamma'], subsetted['gammavcv'])\n",
    "    t2 = time()\n",
    "    print(\"get_global_gamma_estimates {}\".format(t2-t1))\n",
    "    return p_adjusted_gammas, pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_covariate_thing(global_gammas, covariates):\n",
    "    '''\n",
    "    compute the product of global gamma estimates and local covariates\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Numpy Arrray: MxN matrix of IR x covariates  \n",
    "    '''\n",
    "    covs = covariates()\n",
    "    t1 = time()\n",
    "    local_covars = global_gammas*covs\n",
    "    t2 = time()\n",
    "    print(\"do_covariate_thing: {}\".format(t2-t1))\n",
    "\n",
    "    return local_covars\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stack_map_sum(IR_gammas, ds_resampled):\n",
    "    #reshape so we can perform polynomial products\n",
    "    t1 = time()\n",
    "    #reshaped = IR_gammas.reshape(24378,4,4)\n",
    "    t2 = time()\n",
    "    print('reshape {}'.format(t2-t1))\n",
    "    #take the product of each covariate and polynomial tasmax\n",
    "    totals =  np.dot(IR_gammas.T, ds_resampled[0])\n",
    "    #sum across the values and save to dictionary\n",
    "    t3 = time()\n",
    "    print('map totals {}'.format(t3-t2))\n",
    "    summed = {i:x.sum() for i,x in enumerate(totals)}\n",
    "    t4 = time()\n",
    "    print('summed {}'.format(t2-t1))\n",
    "    df = pd.DataFrame.from_dict(summed, orient='index')\n",
    "    t5 = time()\n",
    "    print('todf {}'.format(t5 - t4))\n",
    "    year = pd.DatetimeIndex(ds_resampled.time.data).year[0]\n",
    "    t6 = time()\n",
    "    print(\"datetime: {}\".format(t6-t5))\n",
    "    return df, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xr_reshape(df,year):\n",
    "    #reshape data into xarray dataset\n",
    "    #with appropriate coords,dims, etc\n",
    "    t1 = time()\n",
    "    ds = xr.Dataset(df)\n",
    "    ds.rename({0:'annual impacts', 'dim_0': 'IR_region'}, inplace=True)\n",
    "    _year = pd.DatetimeIndex(start=str(year)+'-01-01', end=str(year)+'-12-31', freq='A')\n",
    "    ds['time'] = _year\n",
    "    t2 = time()\n",
    "    print(\"xr_reshap: {}\".format(t2-t1))\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_covars():\n",
    "    ones = np.ones((24378,4))\n",
    "    covars = np.random.normal(500, 250, size=(24378,12))\n",
    "    new = np.hstack((ones,covars))\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_annual_impact(init_dict):\n",
    "    t1 = time()\n",
    "    ds_resampled, year = do_climate_thing(init_dict['climate_path'],init_dict['variable'], init_dict['resample_dim'], init_dict['resample_method'])\n",
    "    global_gammas, _ = get_global_gamma_estimates(init_dict['csvv_path'], init_dict['pval'], init_dict['prednames'])\n",
    "    IR_gammas = do_covariate_thing(global_gammas, init_dict['ir_covariates'])\n",
    "    df, year = stack_map_sum(IR_gammas, ds_resampled)\n",
    "    ds = xr_reshape(df, year)\n",
    "    t2 = time()\n",
    "    print('Total time for annual impact pipeline: {}'.format(t2 - t1))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_run(list_of_runs, output_dir=None):\n",
    "    '''\n",
    "    Computes impacts by region for a series of years in a specification\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_runs: list of dicts\n",
    "        each dict is a specification for a single year of impacts\n",
    "    \n",
    "    output_dir: str\n",
    "        path where to save file\n",
    "    '''\n",
    "    ds_list = [do_annual_impact(spec) for spec in list_of_runs]\n",
    "    ds = xr.auto_combine(ds_list) \n",
    "    return ds\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import product, combinations\n",
    "paths = glob.glob('/Users/rhodiumgroup/data/gcp_stuff/tasmax_day_aggregated_rcp45_r1i1p1_CCSM4_*.nc')\n",
    "variable = ['tasmax']\n",
    "csvv_path=['/Users/rhodiumgroup/data/gcp_stuff/labor_global_interaction_2factor_BEST_14feb.csvv']\n",
    "pval = [10]\n",
    "prednames = [['tasmax','tasmax2', 'tasmax3', 'tasmax4']]\n",
    "resample_dim = ['A']\n",
    "resample_method = ['mean']\n",
    "ir_covariates= [gen_covars]\n",
    " \n",
    "s = product(paths, variable, csvv_path, pval,  ir_covariates, prednames, resample_dim, resample_method)\n",
    "job_list = []\n",
    "for item in s:\n",
    "    job_spec = dict(climate_path=item[0], \n",
    "                variable=item[1],\n",
    "                csvv_path=item[2], \n",
    "                pval=item[3],\n",
    "                ir_covariates=item[4],\n",
    "                prednames=item[5],\n",
    "                resample_dim=item[6],\n",
    "                resample_method=item[7]\n",
    "                )\n",
    "    job_list.append(job_spec)\n",
    "    \n",
    "#job_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#run = do_run(job_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run.to_netcdf('/Users/rhodiumgroup/data/gcp_stuff/toy_impacts_4_19.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:         (IR_region: 24378, time: 2)\n",
       "Coordinates:\n",
       "  * IR_region       (IR_region) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ...\n",
       "  * time            (time) datetime64[ns] 2006-12-31 2007-12-31\n",
       "Data variables:\n",
       "    annual impacts  (time, IR_region) float64 5.519e+04 1.064e+05 2.139e+05 ..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.open_dataset('/Users/rhodiumgroup/data/gcp_stuff/toy_impacts_4_19.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I need this to load up a bu\n",
    "init_dict = dict(climate_path='/Users/rhodiumgroup/data/gcp_stuff/tasmax_day_aggregated_rcp45_r1i1p1_CCSM4_2006.nc', \n",
    "                variable='tasmax',\n",
    "                csvv_path='/Users/rhodiumgroup/data/gcp_stuff/labor_global_interaction_2factor_BEST_14feb.csvv', \n",
    "                pval=10,\n",
    "                ir_covariates=new,\n",
    "                prednames=['tasmax','tasmax2', 'tasmax3', 'tasmax4'],\n",
    "                resample_dim='A',\n",
    "                resample_method='mean'\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'spline_variables' (time: 3, nterms: 6)>\n",
       "array([[  3.391314e+06,   1.803356e+06,   5.978129e+05,   4.909705e+04,\n",
       "          6.909933e+02,   2.078389e-01],\n",
       "       [  3.512287e+06,   1.848558e+06,   5.803855e+05,   3.597939e+04,\n",
       "          1.172965e+02,   0.000000e+00],\n",
       "       [  3.214724e+06,   1.644738e+06,   4.889150e+05,   2.451471e+04,\n",
       "          3.441414e+01,   0.000000e+00]], dtype=float32)\n",
       "Coordinates:\n",
       "    SHAPENUM  int32 1\n",
       "Dimensions without coordinates: time, nterms\n",
       "Attributes:\n",
       "    long_title: aggregation ofAnnually summed 6 terms obtained by restrict cubic spline on tasin impact regions\n",
       "    units: degree celsius ^ 3\n",
       "    source: Regional aggregated spline variables from /global/scratch/jiacany/nasa_bcsd/spline/tas/rcp85/CCSM4/tas_restrict_cubic_spline_rcp85_r1i1p1_CCSM4_2099.nc"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the temp data for is reduced to this cubic spline thing\n",
    "splined = xr.open_dataset('/Users/rhodiumgroup/data/gcp_stuff/tas_restrict_cubic_spline_aggregate_rcp85_r1i1p1_CCSM4.nc')\n",
    "splined.spline_variables[0:3, 0:6, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "var_tas_monthly = xr.open_dataset('/Users/rhodiumgroup/data/gcp_stuff/tasMonthly_PoPwt_aggregated_IR_rcp85_CCSM4_2016.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rhodiumgroup/anaconda3/envs/geospatial/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Find the mean ir level gdp between two time periods\n",
    "#Find the mean global gdp between two time periods\n",
    "social = pd.read_csv('/Users/rhodiumgroup/data/gcp_stuff/combined.csv',comment='#')\n",
    "interval_mean_ir = social.loc[(social['year'] >= 2001) & (social['year'] <= 2010), ['hierid', 'value']].groupby(['hierid']).mean()\n",
    "interval_mean_global = interval_mean_ir.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-db3d3c234625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load the nightlight data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mglobal_nightlights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/rhodiumgroup/data/gcp_stuff/nightlight_weight.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Data cleaning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#temporarily set zero values to some value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#load the nightlight data. \n",
    "global_nightlights = pd.read_csv('/Users/rhodiumgroup/data/gcp_stuff/nightlight_weight.csv')\n",
    "\n",
    "#Data cleaning\n",
    "#temporarily set zero values to some value\n",
    "global_nightlights.loc[global_nightlights['gdppc_ratio'] == 0.0, 'gdppc_ratio'] = 'hooyah'\n",
    "\n",
    "#Set null or non-existent values to 1\n",
    "global_nightlights.loc[global_nightlights['gdppc_ratio'] == '', 'gdppc_ratio'] = 1.\n",
    "\n",
    "#Now take the global min from the values that have a value\n",
    "glmin = global_nightlights['gdppc_ratio'].min()\n",
    "\n",
    "#assign the min value to the places that were previously zero\n",
    "global_nightlights.loc[global_nightlights['gdppc_ratio'] == 'hooyah', 'gdppc_ratio'] = glmin\n",
    "\n",
    "#fill any nans with ones \n",
    "global_nightlights['gdppc_ratio'] = global_nightlights['gdppc_ratio'].fillna(value=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'global_nightlights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3851555bf468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglobal_nightlights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'global_nightlights' is not defined"
     ]
    }
   ],
   "source": [
    "global_nightlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in gdp data\n",
    "gdppc_merged = pd.read_csv('/Users/rhodiumgroup/data/gcp_stuff/gdppc-merged.csv',comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdppc_merged.iloc[pd.isnull(gdppc_merged).any(1).nonzero()[0]]\n",
    "\n",
    "baseline_means = gdppc_merged.loc[(gdppc_merged['year'] >= 2001) & (gdppc_merged['year'] <= 2010), ['model', 'scenario', 'hierid', 'value']].groupby(['hierid', 'scenario', 'model']).mean()\n",
    "logged_baseline = np.log(baseline_means.value)\n",
    "future_years = gdppc_merged.loc[(gdppc_merged['year'] > 2010)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hierid</th>\n",
       "      <th>scenario</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ABW</th>\n",
       "      <th>SSP1</th>\n",
       "      <th>high</th>\n",
       "      <td>1339.270843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSP2</th>\n",
       "      <th>high</th>\n",
       "      <td>1339.270843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSP3</th>\n",
       "      <th>high</th>\n",
       "      <td>1339.270843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSP4</th>\n",
       "      <th>high</th>\n",
       "      <td>1339.270843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSP5</th>\n",
       "      <th>high</th>\n",
       "      <td>1339.270843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             value\n",
       "hierid scenario model             \n",
       "ABW    SSP1     high   1339.270843\n",
       "       SSP2     high   1339.270843\n",
       "       SSP3     high   1339.270843\n",
       "       SSP4     high   1339.270843\n",
       "       SSP5     high   1339.270843"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_means.head()\n",
    "\n",
    "#gdppc_merged.iloc[pd.isnull(gdppc_merged).any(1).nonzero()[0]]\n",
    "#baseline_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge the two datasets on hierid\n",
    "merged = pd.merge(global_nightlights, gdppc_merged, on='hierid', how= 'inner')\n",
    "#create new column called weights \n",
    "#the value in this column is the gdp weighted by some nightlight ratio\n",
    "#We use the nightlight ratio because?\n",
    "merged['weights'] = merged.gdppc_ratio* merged.value\n",
    "\n",
    "#The output of this is nightlight weighted IR specific GDP values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merged[merged['iso'] == 'AFG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(df.values*df2.values, columns=df.columns, index=df.index)\n",
    "#merged.loc[merged['hierid'] == 'AIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hierid</th>\n",
       "      <th>iso</th>\n",
       "      <th>gdppc_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>AIA</td>\n",
       "      <td>AIA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hierid  iso  gdppc_ratio\n",
       "264    AIA  AIA          1.0"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns the indexes of the \n",
    "#pd.isnull(global_nightlights).any(1).nonzero()[0]\n",
    "#pd.isnull(df).any(1).nonzero()[0]\n",
    "#There are many \n",
    "#pd.isnull(merged).any(1).nonzero()[0]\n",
    "#global_nightlights.loc[global_nightlights['hierid'] == 'AIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes some baseline and then separates the years as before and after baseline\n",
    "#This gives a scenario specific baseline\n",
    "weighted_scenariod_gdp_baselines = merged.loc[merged.year <= 2015].groupby(by=['scenario', 'hierid']).mean()\n",
    "\n",
    "#We need to return this value by ssp and region for our baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popdens = pd.read_csv('/Users/rhodiumgroup/data/gcp_stuff/popop_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weighted_scenariod_gdp_futures = merged.loc[merged.year > 2015].groupby(by=['scenario', 'hierid']).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hierid</th>\n",
       "      <th>iso</th>\n",
       "      <th>gdppc_ratio</th>\n",
       "      <th>year</th>\n",
       "      <th>model</th>\n",
       "      <th>scenario</th>\n",
       "      <th>value</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>high</td>\n",
       "      <td>SSP1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>high</td>\n",
       "      <td>SSP1</td>\n",
       "      <td>1267.326733</td>\n",
       "      <td>1267.326733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>high</td>\n",
       "      <td>SSP1</td>\n",
       "      <td>1411.214953</td>\n",
       "      <td>1411.214953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>high</td>\n",
       "      <td>SSP1</td>\n",
       "      <td>1737.288136</td>\n",
       "      <td>1737.288136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>high</td>\n",
       "      <td>SSP1</td>\n",
       "      <td>2145.161290</td>\n",
       "      <td>2145.161290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hierid  iso  gdppc_ratio  year model scenario        value      weights\n",
       "0    ABW  ABW          1.0  2000  high     SSP1     0.000000     0.000000\n",
       "1    ABW  ABW          1.0  2005  high     SSP1  1267.326733  1267.326733\n",
       "2    ABW  ABW          1.0  2010  high     SSP1  1411.214953  1411.214953\n",
       "3    ABW  ABW          1.0  2015  high     SSP1  1737.288136  1737.288136\n",
       "4    ABW  ABW          1.0  2020  high     SSP1  2145.161290  2145.161290"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gadmid</th>\n",
       "      <th>hierid</th>\n",
       "      <th>color</th>\n",
       "      <th>ISO</th>\n",
       "      <th>popop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28115</td>\n",
       "      <td>CAN.1.2.28</td>\n",
       "      <td>1</td>\n",
       "      <td>CAN</td>\n",
       "      <td>606.338691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28116</td>\n",
       "      <td>CAN.1.17.403</td>\n",
       "      <td>2</td>\n",
       "      <td>CAN</td>\n",
       "      <td>102.876158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28119</td>\n",
       "      <td>CAN.2.34.951</td>\n",
       "      <td>3</td>\n",
       "      <td>CAN</td>\n",
       "      <td>10.799070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28120</td>\n",
       "      <td>CAN.11.259.4274</td>\n",
       "      <td>4</td>\n",
       "      <td>CAN</td>\n",
       "      <td>289.289784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28124</td>\n",
       "      <td>CAN.11.269.4448</td>\n",
       "      <td>5</td>\n",
       "      <td>CAN</td>\n",
       "      <td>0.384870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gadmid           hierid  color  ISO       popop\n",
       "0   28115       CAN.1.2.28      1  CAN  606.338691\n",
       "1   28116     CAN.1.17.403      2  CAN  102.876158\n",
       "2   28119     CAN.2.34.951      3  CAN   10.799070\n",
       "3   28120  CAN.11.259.4274      4  CAN  289.289784\n",
       "4   28124  CAN.11.269.4448      5  CAN    0.384870"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popdens.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
